{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Linear Regression\n",
    "\n",
    "The purpose of this lab is to give you some hands on experience applying linear regression to a real-world dataset. We will use a truncated version of the Divvy Bike Share dataset that we used in the last lecture. \n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this lab, you should gain experience applying linear regression to a real-world dataset, after exploring the linear relationships in the dataset. You will also learn to apply some basic metrics for the goodness of fit of your linear regresison model.\n",
    "\n",
    "After completing this lab, you should be able to: \n",
    "\n",
    "1. Manipulate a dataset in Python/Pandas/Jupyter Notebooks.\n",
    "2. Learn about the importance of pre-processing your dataset, as well as how to do so. You should learn about:\n",
    "    * Various ways to truncate and subset your data.\n",
    "    * Normalizing your dataset in preparation for training and testing.\n",
    "3. Learn how to apply the `scikit-learn` Linear Regression model to a real-world dataset, based on concepts that we covered in class. You should learn about:\n",
    "    * Splitting your data into a training and testing set.\n",
    "    * Creating a model. \n",
    "    * Combining data and metrics from multiple models.\n",
    "4. Learn how to evaluate your model. You should learn how to evaluate the various aspects of feature importance in your dataset, including MAE, MSE and $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and Preparing Your Datasets\n",
    "\n",
    "### 1.1 Load the Divvy Bike Share Data\n",
    "\n",
    "Download the smaller version of the [Divvy Trip data](https://data.cityofchicago.org/Transportation/Divvy-Trips/fg6s-gzvg) that we have provided on Box called `Divvy_Trips_2018.csv.gz`. Load this as a Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets, linear_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "regr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.read_csv(\"/Users/mayar/Downloads/Divvy_Trips_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load the Weather Data from NOAA\n",
    "\n",
    "We have downloaded some historical weather data for Chicago from the National Oceanic and Atmospheric Administration (NOAA) and provided the dataset on Box for download under `chicago-weather.csv.gz`. Load this as a Pandas data frame. \n",
    "\n",
    "If you are curious about how we obtained the dataset, you can read about the available data (and make your own requests) [here](https://www.ncdc.noaa.gov/cdo-web/search).You will also find this [documentation](https://www1.ncdc.noaa.gov/pub/data/cdo/documentation/GHCND_documentation.pdf) about the dataset useful, particularly the part describing the meanings of various columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf = pd.read_csv(\"/Users/mayar/Downloads/chicago-weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Basic Data Analysis and Manipulation\n",
    "\n",
    "We have provided some summary code below from the last lab, formatted to give you a good sense of what the datasets entail, as far as size, dates, and so forth. Note that in this example, the Divvy data frame is called `ddf` and the weather data frame is called `wdf`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a brief review/overview of the data just to see what we have. This is a bit of a review of last week.\n",
    "\n",
    "#### 1.4.1 How many rows are in each dataset, and what date ranges do the dataset span?\n",
    "\n",
    "This one we've done for you, to get you started, since it's a review from last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Divvy Data\n",
    "----------\n",
    "{} Rows\n",
    "First Ride: {}, Last Ride {}\n",
    "\n",
    "Weather Data\n",
    "----------\n",
    "{} Rows\n",
    "First Measurement: {}, Last Measurement {}\n",
    "\"\"\"\n",
    "      .format(\n",
    "          ddf.shape[0],\n",
    "          ddf['START TIME'].min(), \n",
    "          ddf['START TIME'].max(),\n",
    "          wdf.shape[0],\n",
    "          wdf['DATE'].min(),\n",
    "          wdf['DATE'].max()\n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above, first of all, that the date ranges overlap, but that they aren't perfectly overlapping. We'd like to work with data from a common date range from both datasets (and ideally a smaller sample, to start with!) so below we'll ask you to truncate the data.  Before we get there, though, let's try to understand the weather dataset a bit more.\n",
    "\n",
    "#### 1.4.2 Understanding the weather data\n",
    "\n",
    "We can take a quick look at the weather data, since we haven't had the chance to look at that before. Call `describe` to take a look at the overall statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of readings** \n",
    "\n",
    "The first thing you should note is that there are two years of data, but there are different numbers of readings for each type of weather measurement. Based on the summary statistics above, which variable would you suspect reflects one reading per day? Write your answer below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TAVG_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should also immediately see that many of these columns have more than one measurement per day. Try to find out the reason for this. Some of the exercises below walk you through this exploration.\n",
    "\n",
    "**How many unique weather stations are there?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique weather stations: {}\".format(wdf.STATION.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Data Visually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many readings does each weather station have?**\n",
    "\n",
    "Show a plot that has the stations on the x-axis and the number of readings for that station on the y-axis. There are too many stations for a clean x label, so if possible just clean the x-axis up so that there are not a bunch of unreadable names. (We used Seaborn's `lineplot` function which automatically cleans things up, but you are welcome to take a different approach.) Be sure to label your axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf['READINGS'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wwdf = wdf[[\"STATION\", \"READINGS\"]]\n",
    "wwdf = wwdf.groupby('STATION').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set(rc={'figure.figsize':(30, 15)})\n",
    "ax = sns.lineplot(x ='STATION', y = 'READINGS', data=wwdf)\n",
    "ax.set(xlabel=\"WEATHER STATIONS\", ylabel = \"NUMBER OF READINGS\")\n",
    "plt.draw()\n",
    "labels = ax.get_xticklabels()\n",
    "ax.set_xticklabels(labels, rotation=90, fontsize = 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the maximum number of readings that any station has?**\n",
    "\n",
    "Note that this number should make sense, as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The maximum number of readings a stations could have: {}\".format(wwdf['READINGS'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which stations have the maximum number of readings?**\n",
    "\n",
    "Show your answer in a data frame. Hint: There are 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt_df = wwdf[(wwdf['READINGS'] == 730)]\n",
    "rslt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the Datasets\n",
    "\n",
    "### 3.1 Preparing the Weather Data\n",
    "\n",
    "#### 3.1.1 Selecting the appropriate fields\n",
    "\n",
    "**Build a data frame that contains (1) the date (2) the low temperature and (3) the high temperature for the Chicago Midway Airport station. Print the first few rows of the data frame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf[wdf['NAME'].str.contains(\"CHICAGO MIDWAY\")].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf2 = wdf[wdf['STATION'] == 'USC00111577']\n",
    "wdf2 = wdf2[[\"DATE\", \"TMAX\", \"TMIN\"]]\n",
    "wdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the daily high and low temperature for Midway Airport for the duration of the dataset.**\n",
    "\n",
    "Does this match your expectations for what the plot should look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(30, 15)})\n",
    "ax = wdf2.plot(x=\"DATE\", y=\"TMAX\", color=\"r\")\n",
    "ax.set(xlabel=\"DATE\", ylabel = \"TEMPERATURE\")\n",
    "ax2 = ax\n",
    "wdf2.plot(x=\"DATE\", y=\"TMIN\", ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Restricting to 2018 data**\n",
    "\n",
    "You can see from the above that we have weather data through 2019, but we want to work with 2018 only. Truncate the dataset so that it only includes temperatures from 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(s):\n",
    "    dates = {date:pd.to_datetime(date) for date in s.unique()}\n",
    "    return s.map(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf2['DATE'] = lookup(wdf2['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf2 = wdf2[wdf2['DATE'] <= '2018-12-31']\n",
    "wdf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check your work**\n",
    "\n",
    "Now check the shape of your dataset.  You should have a $365x3$ matrix (date, low, high), for each date in 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Preparing the Divvy Data\n",
    "\n",
    "Below will provide some experience with plotting rides over time.\n",
    "\n",
    "#### 3.3.1 Selecting the appropriate rows and columns\n",
    "\n",
    "The Divvy data spans a longer timeframe than the weather data, and so we would like to match these up to the appropriate dates. Also note that the `START_TIME` column is more granular than we need (i.e. we are only concerned with date when merging with the weather data). Group these data so that each entry in the Divvy data corresponds to a single date. \n",
    "\n",
    "Depending on how you performed the last lab, you may or may not be able to re-use some code from last week. Regardless, the `groupby` function should come in handy.\n",
    "\n",
    "**Truncate the data by date**\n",
    "\n",
    "The truncation of the Divvy data is not perfect because it was done by searching and selecting on the CSV. Fix the truncation so that only rides starting in 2018 are included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['TRIPSDAY'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf[['DATE','HOUR']] = ddf['START TIME'].str.split(\" \",n=1,expand=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['DATE'] = lookup(ddf['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.set_index('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.resample('1D').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf2 = ddf.truncate(before = '2018-01-01', after = '2018-12-31') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Grouping by Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already grouped by date after **resampling**\n",
    "ddf2 = ddf2[[\"TRIP DURATION\", \"TRIPSDAY\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group the data by date to get number of rides**\n",
    "\n",
    "Now group the data by date so that we can align it with the weather data. Check the shape of your dataset. It should be $365x2$ (one total ride count per day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which date in 2018 had the most number of rides?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf2[ddf2['TRIPSDAY']==ddf2['TRIPSDAY'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Group the data by date to get total riding time by date**\n",
    "\n",
    "Now group the data by date so that we can align the total ride duration with the weather data. Check the shape of your dataset. It should be $365x2$ (one total duration of rides per day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which date in 2018 had the most riding time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf2[ddf2['TRIP DURATION']==ddf2['TRIP DURATION'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3 Visualizing the Temporal Data \n",
    "As a sanity check that the Divvy data looks good and that there's a linear relationship between the datasets, let's plot the trips and duration by day (as we did last week)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(20, 5)})\n",
    "ax = ddf2['TRIP DURATION'].plot.area()\n",
    "ax.set(ylabel = \"TRIPS PER DAY\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ddf2['TRIPSDAY'].plot(linewidth=1)\n",
    "ax.set(ylabel = \"TRIP DURATION (seconds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Visualizing Relationships\n",
    "\n",
    "We'll now look at a scatterplot of each of these against weather to explore the linear relationship between temperature and ride duration and number of rides.\n",
    "\n",
    "**Join your data into a single dataframe.**\n",
    "\n",
    "You may find it easy/useful to create a single dataframe with all of the data using the `merge` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = ddf2.merge(wdf2, left_index = True, right_on = 'DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = mdf.set_index('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the scatterplots with the temperature and ride relationshps**\n",
    "\n",
    "Provide four scatterplots:\n",
    "1. Ride count vs. low temperature\n",
    "2. Ride count vs. high temperature\n",
    "3. Ride duration vs. low temperature\n",
    "4. Ride duration vs. high temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = sns.scatterplot(x='TMIN', y=\"TRIP DURATION\", data=mdf)\n",
    "ax.set(xlabel=\"Minimum Temperature\", ylabel = \"Trip Duration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"TMAX\", y=\"TRIP DURATION\", data=mdf)\n",
    "ax.set(xlabel=\"Maximum Temperature\", ylabel = \"Trip Duration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"TMIN\", y=\"TRIPSDAY\", data=mdf)\n",
    "ax.set(xlabel=\"Minimum Temperature\", ylabel = \"Number of Rides\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=\"TMAX\", y=\"TRIPSDAY\", data=mdf)\n",
    "ax.set(xlabel=\"Maximum Temperature\", ylabel = \"Number of Rides\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Regression\n",
    "\n",
    "At last, we are ready to apply linear regression to our data!  Note that it took a **long** time to get to this stage. This is pretty much normal for real-world data science applications: You will spend a lot of time cleaning your data before you are ready to get to the machine learning/prediction.\n",
    "\n",
    "### 4.1. Prepare Training and Test Sets\n",
    "\n",
    "Although our data is in the right format, don't forget that you will want to normalize the values in the dataset before applying linear regression.\n",
    "\n",
    "Normalize all of the temperature columns in the dataset to have zero mean and standard deviation of 1. Remember to normalize against the mean and standard deviation of the training sets only, as described [here](https://sebastianraschka.com/faq/docs/scale-training-test.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Split into training and testing\n",
    "\n",
    "Hold out 20% of the dataset for testing. Your test set should be randomly sampled. Be sure to use a random seed.\n",
    "\n",
    "Hint: `scikit-learn` has useful functions for doing this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mdf[['TMAX', 'TMIN']]\n",
    "y = mdf[['TRIP DURATION', 'TRIPSDAY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Normalize the features\n",
    "\n",
    "Normalize the temperatures against the mean and standard deviation from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, df_train):\n",
    "    df_copy = df.copy()\n",
    "    for col in df:\n",
    "        df_copy[col] = ((df.loc[:,(col)] - df_train.loc[:,(col)].mean()) / df_train.loc[:,(col)].std())\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = normalize(X_train, X_train)\n",
    "X_train_normalized.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_normalized = normalize(X_test, X_train)\n",
    "X_test_normalized.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainnorm = pd.DataFrame(normalizer.transform(X_train))\n",
    "X_testnorm = pd.DataFrame(normalizer.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainnorm.describe().round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testnorm.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Apply Linear Regression to Ride Counts\n",
    "\n",
    "Now we're ready to apply linear regression to the datasets! The ride count target `count` appears to have more of a linear relationship with minimum and maximum temperatures. Try those first to see which is the best predictor of `count`.\n",
    "\n",
    "#### 4.2.1 Single-Variable Linear Regression\n",
    "\n",
    "First try each linear regression separately using `scikit-learn`'s `LinearRegression`.  Report the Mean Absolute Error (MAE), Mean Squared Error (MSE) and $R^2$ for each instance.\n",
    "\n",
    "##### 4.2.1.1 Low Temperature\n",
    "\n",
    "**Compute the Linear Regression**\n",
    "\n",
    "Fit a linear regression model for `count` against daily low temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_regression(X_train, X_test, X_train_normalized, X_test_normalized, y_train, y_test, xcolumn, ycolumn):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    target = y_train[ycolumn].values\n",
    "    target_observed = y_test[ycolumn].values\n",
    "    if xcolumn is \"ALL\":\n",
    "        features = X_train_normalized\n",
    "        features_notnorm = X_train\n",
    "        features_test = X_test\n",
    "        features_test_norm = X_test_normalized\n",
    "        regr.fit(features,target)\n",
    "        y_hat = regr.predict(features)\n",
    "        target_predicted = regr.predict(features_test_norm)\n",
    "        return target_predicted, features, target, target_observed, features_notnorm, features_test, features_test_norm, y_hat\n",
    "    else:\n",
    "        features = X_train_normalized[xcolumn].values.reshape(-1,1)\n",
    "        features_notnorm = X_train[xcolumn].values.reshape(-1,1)\n",
    "        features_test = X_test[xcolumn]\n",
    "        features_test_norm = X_test_normalized[xcolumn].values.reshape(-1,1)\n",
    "        regr.fit(features,target)\n",
    "        y_hat = regr.predict(features)\n",
    "        target_predicted = regr.predict(features_test_norm)\n",
    "        return target_predicted, features, target, target_observed, features_notnorm, features_test, features_test_norm, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted, features, target, target_observed, features_notnorm, features_test, features_test_norm, y_hat = do_regression(X_train, X_test, X_train_normalized, X_test_normalized, y_train, y_test, 'TMIN', 'TRIPSDAY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the Best Fit Line Against the Complete Set of Points**\n",
    "\n",
    "Plot minimum temperature against the number of rides in the original units (NOT the normalized units used as features when training the model) for the complete set of 365 points. Add the line of best fit from the model, and be sure to label your axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(features_notnorm, target, '.', color='red', markersize=12)\n",
    "plt.plot(features_test, target_observed, '*', color='green', markersize=10)\n",
    "plt.plot(features_notnorm, y_hat, color='blue', linewidth=3)\n",
    "\n",
    "plt.xlabel('Minimum Temperature')\n",
    "plt.ylabel('Number of Rides')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the Error**\n",
    "\n",
    "Report the Mean Absolute Error (MAE), Mean Squared Error (MSE) and $R^2$ of this model on the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(string, target_observed, target_predicted):\n",
    "    print(string)\n",
    "    print(\" \")\n",
    "    mae = metrics.mean_absolute_error(target_observed, target_predicted)\n",
    "    print(\"Mean Absolute Error:\", mae)\n",
    "    mse = metrics.mean_squared_error(target_observed, target_predicted)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    r_squared = metrics.r2_score(target_observed, target_predicted)\n",
    "    print(\"R^2:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(\"**Error for linear regression model for number of trips against daily low temperatures**\",target_observed, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1.2 High Temperature\n",
    "\n",
    "**Compute the Linear Regression**\n",
    "\n",
    "As above, fit a linear regression model for `count` against daily high temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted, features, target, target_observed, features_notnorm, features_test, features_test_norm, y_hat = do_regression(X_train, X_test, X_train_normalized, X_test_normalized, y_train, y_test, 'TMAX', 'TRIPSDAY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the Best Fit Line Against the Complete Set of Points**\n",
    "\n",
    "As done above, plot maximum temperature against the number of rides in the original units for the complete set of points. Add the line of best fit from the model, and be sure to label your axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(features_notnorm, target, '.', color='red', markersize=12)\n",
    "plt.plot(features_test, target_observed, '*', color='green', markersize=10)\n",
    "plt.plot(features_notnorm, y_hat, color='blue', linewidth=3)\n",
    "\n",
    "plt.xlabel('Minimum Temperature')\n",
    "plt.ylabel('Number of Rides')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute the Error**\n",
    "\n",
    "Report the Mean Absolute Error (MAE), Mean Squared Error (MSE) and $R^2$ of this model on the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(\"**Error for linear regression model for number of trips against daily high temperatures**\",target_observed, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret your results**\n",
    "\n",
    "Which variable (between daily minimum or maximum temperature) is a better predictor of ride count? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Maximum temperature** Its R^2 is bigger which means that it explains better the variance in the number of trips. As well as lower Mean Absolute Error, which is the the average distance between each data point and the mean,\n",
    "and Mean Squared Error._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Multi-Variable Linear Regression\n",
    "\n",
    "Now try a multiple-variable regression with both low and high temperature. Plot your results and report the error.\n",
    "\n",
    "How does it perform compared to the single-variable methods above?  Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted, features, target, target_observed, features_notnorm, features_test, features_test_norm, y_hat = do_regression(X_train, X_test, X_train_normalized, X_test_normalized, y_train, y_test, \"ALL\", \"TRIPSDAY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(\"**Error for linear regression model for number of trips against daily low and high temperatures**\",target_observed, target_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Incorporating more weather data**\n",
    "\n",
    "Include daily precipitation and snowfall from the NOAA data in your multi-variable regression. Remember to normalize the new variables. \n",
    "\n",
    "Of the four variables now in your model, which is the best predictor of ride count? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdf3 = wdf[wdf['STATION'] == 'USC00111577']\n",
    "wdf3 = wdf3[[\"DATE\", \"PRCP\", \"SNOW\", \"TMAX\", \"TMIN\" ]]\n",
    "wdf3['DATE'] = lookup(wdf3['DATE'])\n",
    "wdf3 = wdf3[wdf3['DATE'] <= '2018-12-31']\n",
    "\n",
    "mdf2 = ddf2.merge(wdf3, left_index = True, right_on = 'DATE')\n",
    "mdf2 = mdf2.set_index('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = mdf2[['PRCP','SNOW','TMAX', 'TMIN']]\n",
    "y = mdf2[['TRIP DURATION', 'TRIPSDAY']]\n",
    "\n",
    "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(x,y,test_size=0.20, random_state=42)\n",
    "\n",
    "X_train_norm_m = normalize(X_train, X_train)\n",
    "X_test_norm_m = normalize(X_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted, features, target, target_observed, features_notnorm, features_test, features_test_norm, y_hat = do_regression(X_train_m, X_test_m, X_train_norm_m, X_test_norm_m, y_train_m, y_test_m, \"ALL\", \"TRIPSDAY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(\"**Error for linear regression model for number of trips against daily low and high temperatures ADDED VARIABLES**\",target_observed, target_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_predicted = regr.predict(X_test_norm_m)\n",
    "coeff_df = pd.DataFrame(regr.coef_, X_test.columns, columns=['Coefficient'])  \n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This means that for a unit increase in \"daily precipitation\", there is a decrease of 1,379 rides. For a unit increse in \"snowfall\", there is an increase of ~73 rides. For every unit more in \"maximum temperature\", there is an incrase of ~4,044 rides. Similarly, for every unit increse in \"minimum temperature\", there is an increase of ~1,364 rides. As a conclusion, after running multi-variable regression, apparently \"maximum temperature\" is the best predictor of ride count._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Polynomial Transformations of Predictors\n",
    "\n",
    "Look back at your scatterplot of ride duration vs. daily high/low temperatures. The relationship between temperature and ride duration appears to better fit a polynomial (rather than a linear) function. \n",
    "\n",
    "First fit a linear regression predicting `duration` using the two features of high and low temperatures. Then, apply a polynomial transformation to these predictors (e.g. square them) to see if this yields a better fit. Explain your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_predicted, features, target, target_observed, features_notnorm, features_test, features_test_norm, y_hat = do_regression(X_train, X_test, X_train_normalized, X_test_normalized, y_train, y_test, \"ALL\", \"TRIP DURATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(\"**Error for linear regression model for trip duration against daily low and high temperatures**\",target_observed, target_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree = 2, include_bias = True)\n",
    "pf = poly.fit_transform(X_train_normalized)\n",
    "pft = poly.fit_transform(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptarget_predicted, pfeatures, ptarget, ptarget_observed, pfeatures_notnorm, pfeatures_test, pfeatures_test_norm, py_hat = do_regression(X_train, X_test, pf, pft, y_train, y_test, \"ALL\", \"TRIP DURATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(\"**Error for polynomial regression model for trip duration against daily low and high temperatures**\",ptarget_observed, ptarget_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Regularization\n",
    "\n",
    "We will cover the topic of regularization in class next week. For now, try out the `Ridge` and `Lasso` linear models in place of `LinearRegression`. In particular, explore how different values of the `alpha` parameter affect performance. (Hint: the `scikit-learn` documentation for [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) and [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) will be helpful.) \n",
    "\n",
    "Comment on your results from changing this parameter when fitting models predicting `duration` using the four features used above (minimum temperature, maximum temperature, precipitation, and snowfall). How did changing the regularization parameter affect performance? Note that this question is intentionally meant to be open-ended to give you a chance to experiment with these parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1100,100):\n",
    "    ls = linear_model.Lasso(alpha=i)\n",
    "    rg = linear_model.Ridge(alpha=i)\n",
    "    en = linear_model.ElasticNet(alpha=i)\n",
    "\n",
    "    models = [(ls, 'Lasso'),\n",
    "               (rg, 'Ridge'),\n",
    "               (en, 'Elastic Net')]\n",
    "    print('\\n\\033[1m' + 'Alpha set to: {}'.format(i) + '\\033[0m\\n')\n",
    "    for m in models:\n",
    "        (model,name) = m\n",
    "        model.fit(features, target)\n",
    "        target_predict = model.predict(features_test_norm)\n",
    "        print('{}\\n{}\\n'.format(name,model.coef_))\n",
    "        print_metrics(\"**Error for linear regression model for trip duration against daily low and high temperatures**\",\n",
    "                      target_observed, target_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
